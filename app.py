import streamlit as st
import pandas as pd
import os
import re
import glob
import joblib
import random
import string
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from rdkit import Chem, DataStructs
from rdkit.Chem import AllChem, rdFingerprintGenerator
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
import shap
from Bio import Entrez
from openai import OpenAI
from io import StringIO

# Streamlit page configuration
st.set_page_config(page_title="2025CADDè¯¾ç¨‹å®è·µ", page_icon="ğŸ”¬")

# Helper functions
def create_project_directory():
    project_name = datetime.now().strftime("%Y-%m-%d-%H-%M") + "_" + ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
    project_dir = os.path.join("./projects", project_name)
    os.makedirs(project_dir, exist_ok=True)
    return project_dir

def mol_to_fp(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        fp = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048).GetFingerprint(mol)
        arr = np.zeros((1,))
        DataStructs.ConvertToNumpyArray(fp, arr)
        return arr
    st.warning(f"æ— æ³•è§£æSMILES: {smiles}")
    return [None] * 2048

def display_data_summary(data):
    st.subheader("æ•°æ®é›†æ¦‚å†µ")
    st.write("æ•°æ®çš„åŸºæœ¬ä¿¡æ¯ï¼š")
    st.write(data.info())
    st.write("æè¿°æ€§ç»Ÿè®¡ï¼š")
    st.write(data.describe())

    numeric_columns = data.select_dtypes(include=['number']).columns.tolist()
    st.subheader("æ•°å€¼å‹ç‰¹å¾çš„åˆ†å¸ƒ")
    for col in numeric_columns[:3]:
        st.write(f"{col} çš„åˆ†å¸ƒï¼š")
        fig, ax = plt.subplots()
        sns.histplot(data[col], kde=True, ax=ax)
        ax.set_title(f"{col}")
        st.pyplot(fig)

def preprocess_data(fp_file):
    data = pd.read_csv(fp_file).dropna()
    for col in data.select_dtypes(include=['object']).columns:
        data[col] = pd.to_numeric(data[col], errors='coerce')
    return data.dropna()

def save_input_data_with_fingerprint(data, project_dir, label_column):
    columns_name = next((col for col in ['smiles', 'SMILES'] if col in data.columns), None)
    if not columns_name:
        st.write('Cannot find column named "smiles" or "SMILES" in the dataset!')
        return
    fingerprints = data[columns_name].apply(mol_to_fp)
    fingerprint_df = pd.DataFrame(fingerprints.tolist())
    fingerprint_df['label'] = data[label_column]
    output_file = os.path.join(project_dir, "input.csv")
    fingerprint_df.to_csv(output_file, index=False)
    st.write(f"Fingerprint data saved to {output_file}")
    return output_file

def train_and_save_model(fp_file, project_dir, rf_params):
    data = preprocess_data(fp_file)
    X, y = data.iloc[:, :-1], data.iloc[:, -1]
    st.write("ç‰¹å¾æ•°æ®(X)å½¢çŠ¶ï¼š", X.shape)
    st.write("æ ‡ç­¾æ•°æ®(y)å½¢çŠ¶ï¼š", y.shape)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    model = RandomForestClassifier(**rf_params)
    model.fit(X_train, y_train)

    model_filename = "model.pkl"
    joblib.dump(model, os.path.join(project_dir, model_filename))
    st.write(f"æ¨¡å‹å·²ä¿å­˜åˆ°ï¼š{os.path.join(project_dir, model_filename)}")

    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
    roc_auc = auc(fpr, tpr)

    save_and_display_roc_curve(fpr, tpr, roc_auc, project_dir)
    save_and_display_confusion_matrix(y_test, y_pred, project_dir)
    save_and_display_feature_importance(model, X.columns, project_dir)

    return model, acc, roc_auc

def save_and_display_roc_curve(fpr, tpr, roc_auc, project_dir):
    fig, ax = plt.subplots()
    ax.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
    ax.plot([0, 1], [0, 1], color='gray', linestyle='--')
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.set_title('ROC Curve')
    ax.legend(loc='lower right')
    plt.savefig(os.path.join(project_dir, "roc_curve.png"))
    st.image(os.path.join(project_dir, "roc_curve.png"))

def save_and_display_confusion_matrix(y_test, y_pred, project_dir):
    confusion = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots()
    sns.heatmap(confusion, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_xlabel("Predicted labels")
    ax.set_ylabel("True labels")
    ax.set_title("Confusion Matrix")
    plt.savefig(os.path.join(project_dir, "confusion_matrix.png"))
    st.image(os.path.join(project_dir, "confusion_matrix.png"))

def save_and_display_feature_importance(model, features, project_dir):
    feature_importances = model.feature_importances_
    fig, ax = plt.subplots()
    sns.barplot(x=list(features), y=feature_importances, ax=ax)
    ax.set_title("Feature Importance")
    plt.savefig(os.path.join(project_dir, "feature_importance.png"))
    st.image(os.path.join(project_dir, "feature_importance.png"))

def search_pmc(keyword):
    handle = Entrez.esearch(db="pmc", term=keyword, retmode="xml", retmax=5)
    return Entrez.read(handle)["IdList"]

def fetch_article_details(pmcid):
    handle = Entrez.efetch(db="pmc", id=pmcid, retmode="text")
    return Entrez.read(handle)

# Streamlit UI setup
st.title("2025CADDè¯¾ç¨‹å®è·µ")
sidebar_option = st.sidebar.selectbox("é€‰æ‹©åŠŸèƒ½", ["æ•°æ®å±•ç¤º", "æ¨¡å‹è®­ç»ƒ", "æ´»æ€§é¢„æµ‹", "æŸ¥çœ‹å·²æœ‰é¡¹ç›®", "çŸ¥è¯†è·å–"])

# Data visualization
if sidebar_option == "æ•°æ®å±•ç¤º":
    csv_files = glob.glob("./data/*.csv")
    dataset_choice = st.sidebar.selectbox("é€‰æ‹©æ•°æ®é›†", [os.path.basename(file) for file in csv_files])
    selected_file = csv_files[[os.path.basename(file) for file in csv_files].index(dataset_choice)]
    data = pd.read_csv(selected_file)
    display_data_summary(data)

# Model training
elif sidebar_option == "æ¨¡å‹è®­ç»ƒ":
    csv_files = glob.glob("./data/*.csv")
    dataset_choice = st.sidebar.selectbox("é€‰æ‹©æ•°æ®é›†", [os.path.basename(file) for file in csv_files])
    selected_file = csv_files[[os.path.basename(file) for file in csv_files].index(dataset_choice)]
    data = pd.read_csv(selected_file)

    label_column = st.sidebar.selectbox("é€‰æ‹©æ ‡ç­¾åˆ—", data.columns.tolist())
    rf_params = {
        'n_estimators': st.sidebar.slider("éšæœºæ£®æ— n_estimators", 50, 500, 100),
        'max_depth': st.sidebar.slider("éšæœºæ£®æ— max_depth", 1, 30, 3),
        'max_features': st.sidebar.slider("éšæœºæ£®æ— max_features", 0.1, 1.0, 0.2)
    }

    if st.sidebar.button("å¼€å§‹è®­ç»ƒæ¨¡å‹"):
        project_dir = create_project_directory()
        fp_file = save_input_data_with_fingerprint(data, project_dir, label_column)
        model, acc, roc_auc = train_and_save_model(fp_file, project_dir, rf_params)
        st.write(f"è®­ç»ƒå®Œæˆï¼Œå‡†ç¡®ç‡: {acc:.4f}, AUC: {roc_auc:.4f}")

# Predictive model
elif sidebar_option == "æ´»æ€§é¢„æµ‹":
    projects = glob.glob('./projects/*')
    if not projects:
        st.write("æ²¡æœ‰æ‰¾åˆ°å·²è®­ç»ƒçš„é¡¹ç›®")
    else:
        project_names = [os.path.basename(project) for project in projects]
        project_name = st.selectbox("é€‰æ‹©ä¸€ä¸ªé¡¹ç›®è¿›è¡Œé¢„æµ‹", project_names)
        selected_project_dir = os.path.join("./projects", project_name)
        model_filename = os.path.join(selected_project_dir, "model.pkl")
        
        if os.path.exists(model_filename):
            model = joblib.load(model_filename)
            st.write(f"åŠ è½½æ¨¡å‹ï¼š{model_filename}")

            smiles_input = st.text_input("è¾“å…¥åˆ†å­SMILES")
            if smiles_input:
                fingerprint = mol_to_fp(smiles_input)
                if fingerprint is not None:
                    prediction = model.predict([fingerprint])
                    prob = model.predict_proba([fingerprint])[:, -1]
                    st.write(f"é¢„æµ‹ç»“æœ: {prediction[0]}, æ¦‚ç‡: {prob[0]}")

                    explainer = shap.TreeExplainer(model)
                    shap_values = explainer.shap_values(fingerprint)
                    fig, ax = plt.subplots()
                    shap.summary_plot(shap_values, features=fingerprint, show=False)
                    st.pyplot(fig)
        else:
            st.write("æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·ç¡®ä¿è¯¥é¡¹ç›®å·²è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹ã€‚")

# Existing projects
elif sidebar_option == "æŸ¥çœ‹å·²æœ‰é¡¹ç›®":
    display_existing_projects()

# Knowledge retrieval from PubMed
elif sidebar_option == "çŸ¥è¯†è·å–":
    Entrez.email = "your_email@example.com"
    keyword = '"Clinical Toxicology" and "Chemical"'
    pmcid_list = search_pmc(keyword)
    st.write(f"å…³é”®è¯: {keyword}")
    st.write(f'æœç´¢åˆ°çš„ç›¸å…³æ–‡çŒ®(å‰äº”ç¯‡): {list(pmcid_list)}')

    pmcid = '11966747'
    article_details = fetch_article_details(pmcid)
    st.write(f'ä»PMCè·å–æ–‡çŒ®"{pmcid}"å…¨æ–‡: ')
    title = article_details[0]['front']['article-meta']['title-group']['article-title'].replace('\n', '')
    abstract = article_details[0]['front']['article-meta']['abstract'][0]['p'][1].replace('\n', '')
    st.info(f'é¢˜ç›®: {title}')
    st.info(f'æ‘˜è¦: {abstract}')
    full_text = ""
    for i in article_details[0]['body']['sec']:
        for j in i['p']:
            full_text += re.sub(r'<.*?>', '', j.replace('\n', ''))+'\n'
    st.text_area("å…¨æ–‡", full_text, height=300)

    key = st.text_input("è¯·è¾“å…¥æ‚¨çš„OpenAI Keyç”¨äºè§£ææ–‡çŒ®çŸ¥è¯†", "")
    if key:
        os.environ["OPENAI_API_KEY"] = key
        client = OpenAI()
        query = """è¯·ä»ä»¥ä¸‹æ–‡çŒ®ä¸­æå–ä¸æ¯’å‰¯ä½œç”¨ç›¸å…³çš„åŒ–åˆç‰©ä¿¡æ¯ï¼ŒåŒ…æ‹¬åå­—ï¼Œç±»å‹å’Œæ¯’å‰¯ä½œç”¨æè¿°ï¼š\n""" + abstract
        response = client.responses.create(model="gpt-4", input=query)
        st.write(response.output_text)
